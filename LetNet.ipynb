{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Giới thiệu**\n",
        "- Trong bài tập về nhà lần này, chúng ta sẽ implement mạng LeNet sử dụng PyTorch, và chúng ta sẽ train và đánh giá mô hình trên tập dữ liệu FashionMNIST.\n",
        "- Dưới đây là kiến trúc mô hình mà chúng ta sẽ implement: ![](https://drive.google.com/uc?export=view&id=1MyiyOZnioz2WegCNjhyv_VXETFPYn_yN)\n",
        "\n"
      ],
      "metadata": {
        "id": "KJTHW6i1SRgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FashionMNIST dataset** \n",
        "Giới thiệu về Dataset\n",
        "\n",
        "Fashion-MNIST là một tập dữ liệu về các hình ảnh bài viết của Zalando — bao gồm một tập huấn luyện gồm 60.000 mẫu và một tập test 10.000 mẫu. Mỗi mẫu là một hình ảnh grayscale 28x28, được liên kết với một nhãn từ 10 lớp. Zalando dự định Fashion-MNIST sẽ phục vụ như một sự thay thế trực tiếp cho tập dữ liệu MNIST ban đầu cho các thuật toán máy học điểm chuẩn. Nó có cùng kích thước hình ảnh và cấu trúc của các phần đào tạo và thử nghiệm.\n",
        "\n",
        "Mỗi hình ảnh có chiều cao 28 pixel và chiều rộng 28 pixel, tổng cộng là 784 pixel. Mỗi pixel có một giá trị pixel duy nhất được liên kết với nó, cho biết độ sáng hoặc tối của pixel đó, với các con số cao hơn có nghĩa là tối hơn. Giá trị pixel này là một số nguyên từ 0 đến 255. Tập dữ liệu đào tạo và kiểm tra có 785 cột. Cột đầu tiên bao gồm các nhãn lớp (xem ở trên) và đại diện cho mặt hàng quần áo. Phần còn lại của các cột chứa các giá trị pixel của hình ảnh được liên kết.\n",
        "\n",
        "**Label**\n",
        "\n",
        "0 T-shirt/top\n",
        "\n",
        "1 Trouser\n",
        "\n",
        "2 Pullover\n",
        "\n",
        "3 Dress\n",
        "\n",
        "4 Coat\n",
        "\n",
        "5 Sandal\n",
        "\n",
        "6 Shirt\n",
        "\n",
        "7 Sneaker\n",
        "\n",
        "8 Bag\n",
        "\n",
        "9 Ankle boot"
      ],
      "metadata": {
        "id": "sdVtBXprTOBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "zRURmtRwqEit"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ19LKc1sWwt"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azKN_M4XqLOg"
      },
      "source": [
        "## Setup\n",
        "\n",
        "- Chúng ta sẽ setup một số hyper-parameters cũng như một số giá trị cần dùng theo hướng dẫn nhé\n",
        "- Ở đây, các bạn vào Runtime, chọn Change the runtime type và chọn GPU nhé."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download MNIST dataset in local system"
      ],
      "metadata": {
        "id": "ZXh0tUwrsO13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Định nghĩa tham số transform\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(), # Chuyển ảnh sang dạng Tensor\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize ảnh với mean và standard deviation là 0.5\n",
        "    ])\n",
        "\n",
        "# Load the train and test data\n",
        "train_set = torchvision.datasets.FashionMNIST(root = \"data\", train=True, download=True, transform = transform)\n",
        "test_set = torchvision.datasets.FashionMNIST(root = \"data\", train=False, download=True, transform = transform)\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "OtM8WibZsURb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm thử số chiều của dataset\n",
        "print('The dimension of the train data:')\n",
        "print(train_set.data.size())\n",
        "print('\\nThe dimension of the train labels:')\n",
        "print(train_set.targets.size())\n",
        "\n",
        "print('\\n\\nThe dimension of the validation data:')\n",
        "print(test_set.data.size())\n",
        "print('\\nThe dimension of the validation labels:')\n",
        "print(test_set.targets.size())"
      ],
      "metadata": {
        "id": "ylBAXk7FXCNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of FashionMNIST dataset"
      ],
      "metadata": {
        "id": "3kX1gJy0vN-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10, 8))\n",
        "cols, rows = 5, 5\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "    img, label = train_set[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XmIAg1JjvmMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "Gbr4IZpTJSgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Số classes trong tập FashionMNIST\n",
        "num_classes = None\n",
        "\n",
        "# Số epoch\n",
        "epochs = 2\n",
        "\n",
        "# Các tham số cần thiết trong quá trình training\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "display_step = 100\n",
        "\n",
        "# Model path\n",
        "checkpoint = 'model.pth'\n",
        "\n",
        "# Khởi tạo một số list để lưu loss và accuracy\n",
        "loss_epoch_array = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "valid_accuracy = []\n",
        "\n",
        "# device: cuda\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "YGR1-nRKIvrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing data for training with DataLoaders\n",
        "- Để tiện cho việc xử lý dữ dữ liệu vào các batches cũng như reshuffle dữ liệu qua mỗi epoch thì chúng ta sẽ sử dụng hàm sẵn có của PyTorch là [DataLoader](https://pytorch.org/docs/stable/data.html) "
      ],
      "metadata": {
        "id": "sKxHkWH6vxsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(None , batch_size=None, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(None, batch_size=None, shuffle = False)"
      ],
      "metadata": {
        "id": "ElcQVzmhw9oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6EMkw45qTuh"
      },
      "source": [
        "## Model\n",
        "\n",
        "- Dưới đây là kiến trúc mô hình mà chúng ta sẽ implement: ![](https://drive.google.com/uc?export=view&id=1MyiyOZnioz2WegCNjhyv_VXETFPYn_yN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geui1VFQwVXk"
      },
      "source": [
        "class CNN_Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN_Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(None, None, None)\n",
        "        self.conv2 = nn.Conv2d(None, None, None)\n",
        "        self.max_pool1 = nn.MaxPool2d(None, None)\n",
        "        self.max_pool2 = nn.MaxPool2d(None)\n",
        "        self.fc1 = nn.Linear(None, None)\n",
        "        self.fc2 = nn.Linear(None, None)\n",
        "        self.fc3 = nn.Linear(None, None)\n",
        "        # self.dropout = nn.Dropout(p=0.3)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ### START CODE HERE ≈ 9-15 lines\n",
        "\n",
        "        ### END CODE HERE\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo model instance và đưa vào device\n",
        "model = None\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "id": "lTwPszPn6CAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training phase\n",
        "\n"
      ],
      "metadata": {
        "id": "g0tv4yZgCQs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "p3yC8RaBMEy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Định nghĩa hàm khởi tạo tham số\n",
        "def weights_init(model):\n",
        "    if isinstance(model, nn.Linear):\n",
        "        # Xavier Distribution\n",
        "        torch.nn.init.xavier_uniform_(model.weight)\n",
        "\n",
        "# Định nghĩa hàm train\n",
        "def train(dataloader, epoch):\n",
        "    loss_epoch = 0\n",
        "    for i, (data,targets) in enumerate(dataloader):\n",
        "        # Đưa dữ liệu vào GPU\n",
        "        data, targets = None, None\n",
        "\n",
        "        # Clear gradient\n",
        "        None\n",
        "        outputs = cnn_net(data)\n",
        "\n",
        "        # Backpropagation, compute gradients\n",
        "        loss = loss_function(outputs, targets)\n",
        "        None\n",
        "\n",
        "        # Apply gradients\n",
        "        None\n",
        "        \n",
        "        # Lưu lại loss\n",
        "        loss_epoch += None\n",
        "        if i % display_step == 0:\n",
        "            accuracy = float(test(test_loader))\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}, Accuracy: {:.4f}%'.format(\n",
        "                epoch + 1, i * 32, len(dataloader.dataset), 100.0 * i / len(dataloader), \n",
        "                loss.item(), accuracy))\n",
        "    return loss_epoch\n",
        "\n",
        "# Định nghĩa hàm test\n",
        "def test(dataloader):\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for i, (data, targets) in enumerate(dataloader):\n",
        "        data, targets = None, None\n",
        "        outputs = cnn_net(data)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        test_loss += targets.size(0)\n",
        "        correct += torch.sum(pred == targets)\n",
        "    return 100.0 * correct / test_loss"
      ],
      "metadata": {
        "id": "F3cJ77VbY7XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo một instance của model và vào GPU\n",
        "cnn_net = None\n",
        "\n",
        "# Khỏi tạo weight với hàm đã tạo\n",
        "cnn_net.apply(weights_init)\n",
        "\n",
        "# Sử dụng loss funtion Cross Entropy Loss\n",
        "loss_function = None\n",
        "\n",
        "# Sử dụng Adam optimizer\n",
        "optimizer = None\n",
        "\n",
        "# Print structure of model\n",
        "print(cnn_net)"
      ],
      "metadata": {
        "id": "eZW7WsUacCN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ycsK9EWz1vc"
      },
      "source": [
        "# Driver code to iterate through epochs and store loss and accuracy\n",
        "for epoch in range(epochs):\n",
        "    loss_epoch = 0\n",
        "    loss_epoch = train(None, None)\n",
        "    loss_epoch_array.append(None)\n",
        "    \n",
        "    train_accuracy.append(test(None))\n",
        "    valid_accuracy.append(test(None))\n",
        "    print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n",
        "                                        loss_epoch_array[-1], train_accuracy[-1], valid_accuracy[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot model history\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "epochs = range(epochs)\n",
        "plt.plot(epochs, train_accuracy, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, valid_accuracy, 'b', label='Test accuracy')\n",
        "plt.title('Training and Test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mQm2jU9_ZYSv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}