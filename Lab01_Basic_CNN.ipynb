{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrR5fQm7p_Zs"
      },
      "source": [
        "##  **Giới thiệu**\n",
        "\n",
        "Trong bài này, chúng ta sử dụng PyTorch để xây dựng một mạng CNN đơn giản. Sau đó chúng ta sẽ huấn luyện và đánh giá model với tập dữ liệu MNIST nhé.\n",
        "\n",
        "## Lưu ý về cách làm bài tập\n",
        "Các bạn điền vào phần **None** và các đoạn code đã được ẩn đi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff69GG6MqBL4"
      },
      "source": [
        "### Tổng quan một mạng CNN cơ bản\n",
        "\n",
        "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
        "\n",
        "### MNIST dataset\n",
        "\n",
        "Trong bài tập này, chúng ta sẽ sử dựng tập MNIST rất nổi tiếng vể  các chữ số viết tay từ 0->9. Tập dataset này bao gồm 60000 ảnh cho training và 10000 ảnh cho testing. Các bức ảnh này đều đã được căn giữa và chỉnh với kích thước cố định là 28x28.\n",
        "\n",
        "Trong phần tiền xử lý, chúng ta sẽ cần chuẩn hóa các giá trị pixel của mỗi ảnh về khoảng [0,1], kiểu dữ liệu sẽ là float32\n",
        "\n",
        "<!-- ![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png) -->\n",
        "\n",
        "Chi tiết tại: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "zRURmtRwqEit"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ19LKc1sWwt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azKN_M4XqLOg"
      },
      "source": [
        "## **Setup**\n",
        "\n",
        "- Chúng ta sẽ setup một số hyper-parameters cũng như một số giá trị cần dùng theo hướng dẫn nhé\n",
        "- Ở đây, các bạn vào Runtime, chọn Change the runtime type và chọn GPU nhé."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "Gbr4IZpTJSgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Số classes trong tập MNIST\n",
        "num_classes = None\n",
        "\n",
        "# Số epoch\n",
        "epochs = None\n",
        "\n",
        "# Các tham số cần thiết trong quá trình training\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "display_step = 100\n",
        "\n",
        "# Model path\n",
        "checkpoint = 'model.pth'\n",
        "\n",
        "# device: cuda\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "YGR1-nRKIvrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download MNIST dataset in local system"
      ],
      "metadata": {
        "id": "ZXh0tUwrsO13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Định nghĩa tham số transform\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(), # Chuyển ảnh sang dạng Tensor\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize ảnh với mean và standard deviation là 0.5\n",
        "    ])\n",
        "\n",
        "# Load MNIST dataset từ torchvision.datasets\n",
        "train_data = datasets.MNIST(\n",
        "    root='data', \n",
        "    train=True, \n",
        "    transform=transform, \n",
        "    download=True\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root='data', \n",
        "    train=False, \n",
        "    transform=transform,\n",
        ")\n"
      ],
      "metadata": {
        "id": "OtM8WibZsURb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "y07UF0b5tEV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.data.size())\n",
        "print(train_data.targets.size())"
      ],
      "metadata": {
        "id": "mO0KTE6Zu2k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of MNIST dataset**"
      ],
      "metadata": {
        "id": "3kX1gJy0vN-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10, 8))\n",
        "cols, rows = 5, 5\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XmIAg1JjvmMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing data for training with DataLoaders\n",
        "- Để tiện cho việc xử lý dữ dữ liệu vào các batches cũng như reshuffle dữ liệu qua mỗi epoch thì chúng ta sẽ sử dụng hàm sẵn có của PyTorch là [DataLoader](https://pytorch.org/docs/stable/data.html) "
      ],
      "metadata": {
        "id": "sKxHkWH6vxsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(None, batch_size=None)\n",
        "test_loader = torch.utils.data.DataLoader(None, batch_size=None)"
      ],
      "metadata": {
        "id": "ElcQVzmhw9oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6EMkw45qTuh"
      },
      "source": [
        "## **Model**\n",
        "\n",
        "- Trong bài này, chúng ta sẽ định nghĩa một class Net để xây dựng một model có cấu trúc như hình ở đầu notebook. Tuy nhiên, ở đây để tránh khả năng bị overfitting của mô hình thì layer `Dropout` sẽ được thêm vào. Mô hình sẽ có cấu trúc như sau: `3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear`\n",
        "- Kích thước ảnh đầu vào: (28, 28, 1)\n",
        "- Ở đây, các layer `Conv2d` có các thông số lần lượt là: `filter = (32, 64, 64); kernel_size = 3; stride = 1; valid padding`\n",
        "- Các layer `Linear` lần lượt số node là `128, 64, num_classes`\n",
        "- Sau layer `MaxPool2d` thì `height` và `width` của ảnh sẽ giảm đi một nửa\n",
        "- Hệ số layer `Dropout` = 0.5\n",
        "- Tham khảo: [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html), [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geui1VFQwVXk"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "        self.relu = None\n",
        "        self.dropout = None\n",
        "        self.flatten = None\n",
        "        self.conv1 = nn.Conv2d(in_channels=None, out_channels=None, kernel_size=None, stride=None, padding=None)\n",
        "        self.conv2 = nn.Conv2d(in_channels=None, out_channels=None, kernel_size=None, stride=None, padding=None)\n",
        "        self.conv3 = nn.Conv2d(in_channels=None, out_channels=None, kernel_size=None, stride=None, padding=None)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=None, stride=None)\n",
        "        self.fc1 = nn.Linear(in_features=None, out_features=None)\n",
        "        self.fc2 = nn.Linear(in_features=None, out_features=None)\n",
        "        self.fc3 = nn.Linear(in_features=None, out_features=None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### START CODE HEAR ≈ 9-18 lines\n",
        "        ## 3x(Conv2d -> ReLU) -> MaxPool -> Dropout -> Flatten -> 2x(Linear ->  ReLU) -> Linear\n",
        "\n",
        "\n",
        "        ### END CODE HERE\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model vào GPU, ví dụ: input = model().to(device)\n",
        "model = None\n",
        "summary(model, (1, 32, 32))"
      ],
      "metadata": {
        "id": "oXLRs7zy7ygB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training phase**\n",
        "\n"
      ],
      "metadata": {
        "id": "g0tv4yZgCQs9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ycsK9EWz1vc"
      },
      "source": [
        "# Define loss and optimizer\n",
        "criterion = None # CrossEntropy\n",
        "optimizer = None # Adam Optimizer set params=model.parameters(), lr=learning_rate\n",
        "best_val_loss = 999\n",
        "\n",
        "# Loop for each epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # Quá trình training \n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Load dữ liệu vào GPU\n",
        "        data, target = None, None\n",
        "\n",
        "        # Clear gradients cho mỗi batch\n",
        "        None # zero grad\n",
        "        output = model(data)\n",
        "\n",
        "        # Backpropagation, tính gradients\n",
        "        loss = criterion(output, target)\n",
        "        None #backward\n",
        "\n",
        "        # Apply gradients để update lại tham số\n",
        "        None\n",
        "        if batch_idx % display_step == 0:\n",
        "            print('Train Epoch {}: [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "    # Quá trình testing \n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Set no grad cho quá trình testing\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # Load dữ liệu vào GPU\n",
        "            data, target = None, None\n",
        "            output = model(data)\n",
        "            output = None # sử dụng hàm log_sotmax của pytorch để tính xác suất cho output, dim = 1\n",
        "            test_loss += criterion(output, target)\n",
        "            pred = None # Sử dụng hàm argmax để lấy predicted label, chú ý keepdim=True\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(None) \n",
        "    if test_loss < best_val_loss:\n",
        "      best_val_loss = test_loss\n",
        "      torch.save(model.state_dict(), checkpoint)  # Lưu model path\n",
        "      print(\"***********    TEST_ACC = {:.2f}%    ***********\".format(correct/100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC0dpWjs1Ivj"
      },
      "source": [
        "# Load lại model đã train\n",
        "model.load_state_dict(torch.load(checkpoint))\n",
        "\n",
        "# Xem lại thông số của model \n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediction**"
      ],
      "metadata": {
        "id": "uVOTLx8zWfxl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC260iYZ1xwt"
      },
      "source": [
        "# Lấy ra một batch trong tập test\n",
        "item = iter(test_loader)\n",
        "data, target = item.next()\n",
        "\n",
        "# Lấy random index của một phần tử trong batch đó\n",
        "test_idx = random.choice(range(len(data)))\n",
        "\n",
        "# Lấy một ví dụ trong tập test\n",
        "data = data[test_idx]\n",
        "target = target[test_idx]\n",
        "assert data.shape == (1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kejuKZIY11hM"
      },
      "source": [
        "# Predict sử dụng model đã train\n",
        "def plot(data, model):\n",
        "  data = torch.unsqueeze(data, dim=0) # unsqueeze data\n",
        "  data = None # Đưa data vào GPU\n",
        "  output = model(data)\n",
        "  output = None # Tính xác suất từng class của output, sử dụng log_softmax, dim = 1\n",
        "  pred = None # Lấy class có xác suất cao nhất, keep dim = True, sử dụng argmax\n",
        "  print(\"Predict Number : \", pred[0][0].detach().cpu().numpy()) \n",
        "  plt.imshow(data[0][0].detach().cpu().numpy(), cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAvIv7Mj2L3K"
      },
      "source": [
        "plot(data, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Exercises"
      ],
      "metadata": {
        "id": "2aUkzj9ckWq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: VGG-like model\n",
        "* Implement a simplified VGG model by building 3 'blocks' of 2 convolutional layers each\n",
        "* Do MaxPooling after each block\n",
        "* The first block should use at least 32 filters, later blocks should use more\n",
        "* You can use 3x3 filters\n",
        "* Use zero-padding to be able to build a deeper model (see the `padding` attribute)\n",
        "* Use a dense layer with at least 128 hidden nodes.\n",
        "* You can use ReLU activations everywhere (where it makes sense)\n",
        "* Plot and interpret the learning curves"
      ],
      "metadata": {
        "id": "8OiAuz5Pkakk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Regularization\n",
        "* Explore different ways to regularize your VGG-like model\n",
        "  * Try adding some dropout after every MaxPooling and Dense layer.\n",
        "    * What are good Dropout rates? Try a fixed Dropout rate, or increase the rates in the deeper layers.\n",
        "  * Try batch normalization together with Dropout\n",
        "    * Think about where batch normalization would make sense \n",
        "* Plot and interpret the learning curves\n"
      ],
      "metadata": {
        "id": "sekBLAzMkrHB"
      }
    }
  ]
}